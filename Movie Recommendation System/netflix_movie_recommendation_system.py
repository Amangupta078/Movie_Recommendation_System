# -*- coding: utf-8 -*-
"""Netflix_movie_Recommendation_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11tfsd2ECKIZztCkUuW0xM_fmC5wtI5Jj
"""

nltk.download('stopwords')

import numpy as np
import pandas as pd

import re
import ast
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer

from warnings import filterwarnings
filterwarnings('ignore')

movies = pd.read_csv('tmdb_5000_movies.csv')
credits = pd.read_csv('tmdb_5000_credits.csv')

movies.head()

credits.head()

movies.shape,credits.shape

"""## **Join the both files**"""

movies = movies.merge(credits,on='title')

movies.head()



movies.shape

movies.columns

"""## **Feature Extraction**

## **Choosing The Relevent Features**

*   Generes
*   Id
*   Keywords
*   Title
*   Movie_id
*   Cast
*   Crew
*   Overview
"""

df= movies[["movie_id","genres","title","keywords","overview","cast","crew"]]

df.head()

df.shape

"""## **Missing data**"""

df.isnull().sum()

df.dropna(inplace=True)

df.isnull().sum()

"""# **Data Cleaning And Optimization**"""

#Genres
df["genres"]

df["genres"][0]

l=ast.literal_eval(df["genres"][0])
l

for i in l:
  print(i["name"])

def fetch_genre(text):
  L=[]
  for i in ast.literal_eval(text):
    L.append(i["name"])
  return L

fetch_genre(df["genres"][0])

df["genres"]=df["genres"].apply(fetch_genre)

df["genres"]

df.head()

#Keywords
df["keywords"][0]

df["keywords"][4085]

def fetch_keywords(object):
  L=[]
  for i in ast.literal_eval(object):
    L.append(i["name"])
  return L

fetch_keywords(df["keywords"][4085])

fetch_keywords(df["keywords"][4807])

df["keywords"]=df["keywords"].apply(fetch_keywords)

df

#cast
df["cast"][0]

def fetch_Cast(text):
  C=[]
  counter =0
  for i in ast.literal_eval(text):
    if counter !=3:
      C.append(i["name"])
      counter +=1


  return C

fetch_Cast(df["cast"][0])

df["cast"]=df["cast"].apply(fetch_Cast)

df.head()

#crew
df["crew"][0]

def fetch_director(text):
  D=[]
  for i in ast.literal_eval(text):
    if i["job"]=="Director":
      D.append(i["name"])
  return D

fetch_director(df["crew"][0])

df["crew"]=df["crew"].apply(fetch_director)

df.head()

#overview
df["overview"][0]

df

df["overview"].str.split()

df["overview"]=df["overview"].apply(lambda x:x.split())

df

df["tags"]=df["genres"]+df["keywords"]+df["cast"]+df["crew"]+df["overview"]

df

df["tags"]=df["overview"].apply(lambda x:[i.replace(" ","")for i in x])

df

df["tags"].apply(lambda x:[i.replace(" ","")for i in x])

df["tags"]=df["tags"].apply(lambda x:" ".join(x))

movie=df[["movie_id","title","tags"]]

movie

movie["tags"][0]

"""# **Now I Will Start With NLP concepts and Text Preprodcessing**


*   Remove Punctuation
*   Lower Case
*   Tokenization
*   Remove Stopwords
*   Encoding


"""

movie["tags"][0]

ps= PorterStemmer()


def text_preprocessing(text):
  cleaned_data= re.sub("[^a-zA-Z]"," ",text)
  lower=cleaned_data.lower()
  token=lower.split()
  stem_data=[ps.stem(word) for word in token if not word in stopwords.words("english")]
  processed_data= " ".join(stem_data)

  return processed_data

movie["tags"]=movie["tags"].apply(text_preprocessing)

movie.head()

movie["tags"][2]

"""## **Use TFIDF Method To Encode The Data**"""

movie["tags"][0]

Tfidf = TfidfVectorizer(max_features=5000)

vectors=Tfidf.fit_transform(movie["tags"]).toarray()
vectors

vectors.shape

Tfidf.get_feature_names_out()

for i in Tfidf.get_feature_names_out():
  print(i)

"""# **Cosine Similarity To recommend a movie**"""

from sklearn.metrics.pairwise import cosine_similarity

Similarity=cosine_similarity(vectors)

Similarity

#Most similar movie of first index
movie_list=sorted(list(enumerate(Similarity[0])),reverse=True,key=lambda x:x[1])[1:6]
movie_list

"""# **Final Recommendation Function**"""

def recommend(movies):
  movie_index=movie[movie["title"]==movies].index[0]
  distances=Similarity[movie_index]
  movies_list=sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]

  for i in movies_list:
    print(movie.iloc[i[0]].title)

recommend("Avatar")

recommend("Titanic")

recommend("Iron Man")

"""## **Creating Pickle Files**"""

import pickle

movie.to_dict()

Similarity

pickle.dump(movie.to_dict(),open("movie_dict.pkl","wb"))
pickle.dump(Similarity,open("similarity.pkl","wb"))









